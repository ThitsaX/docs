{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83d\udcd8 ThitsaWorks Platform Documentation","text":"<p>Welcome to the technical documentation for platform security and architecture within the Mojaloop ecosystem.</p> <p>This documentation describes how the platform is actually implemented, secured, deployed, and operated in real-world environments.</p> <p>It focuses on:</p> <ul> <li>Practical architecture</li> <li>Production security controls</li> <li>Deployment models</li> <li>Operational behavior</li> <li>Integration patterns</li> </ul> <p>This is implementation-driven documentation, not theoretical reference material.</p>"},{"location":"#getting-started","title":"\ud83d\ude80 Getting Started","text":"<p>Choose the deployment model that matches your environment:</p> <ul> <li>Deploy Mojaloop Locally (MicroK8s)</li> <li>Deploy Mojaloop Locally (Without Kubernetes)</li> <li>Deploy Mojaloop Payment Manager (On-Premise)</li> </ul>"},{"location":"#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<ul> <li>Platform Architecture Overview   Provides a high-level reference architecture covering:</li> <li>Mojaloop Hub, PM4ML, and Tazama</li> <li>Cloud, on-premise, and hybrid deployments</li> <li>Primary\u2013Standby topology</li> <li>Platform responsibilities and trust boundaries</li> </ul>"},{"location":"#security-architecture","title":"\ud83d\udd10 Security Architecture","text":"<ul> <li>Hub \u2194 PM4ML Security Architecture   Describes the end-to-end security model between the Hub and PM4ML, including:</li> <li>Mutual TLS (mTLS) for transport-level security  </li> <li>JWS for application-level message signing  </li> <li>Certificate lifecycle and rotation  </li> <li>Trust boundaries and ownership  </li> </ul>"},{"location":"#operations-reliability","title":"\u2699\ufe0f Operations &amp; Reliability","text":"<p>The following sections are being developed and will reflect validated production behavior:</p> <ul> <li>\ud83d\udd01 Certificate &amp; Key Management  </li> <li>\ud83d\udea8 Incident &amp; Failure Scenarios  </li> <li>\ud83d\udcd0 Environment &amp; Capacity Model  </li> <li>\ud83d\udcca Monitoring &amp; Alerting Architecture  </li> <li>\ud83e\uddfe Operational Runbooks  </li> </ul>"},{"location":"#more-information","title":"\ud83c\udf10 More Information","text":"<p>For general information about ThitsaWorks, including services and platform offerings:</p> <p>\ud83d\udc49 https://thitsaworks.com</p>"},{"location":"#about-this-site","title":"\ud83d\udccc About This Site","text":"<p>This documentation reflects real-world implementation and operational security practices used in Mojaloop-based deployments.</p> <p>It is intended for:</p> <ul> <li>Platform Engineers  </li> <li>Security Engineers  </li> <li>Infrastructure Engineers  </li> <li>DFSP Integration Teams  </li> <li>Operations Teams  </li> </ul> <p>The goal is to provide a clear, practical, and production-aligned understanding of how the system is secured, deployed, and operated.</p>"},{"location":"deploy-mojaloop-local-microk8s/","title":"\ud83d\ude80 Deploy Mojaloop Locally Using MicroK8s (Ubuntu 24.04 LTS)","text":""},{"location":"deploy-mojaloop-local-microk8s/#introduction","title":"\ud83d\udcd8 Introduction","text":"<p>This guide explains how to deploy a full Mojaloop environment locally using:</p> <ul> <li>Ubuntu 24.04 LTS</li> <li>MicroK8s</li> <li>Helm</li> </ul> <p>The setup includes:</p> <ul> <li>Mojaloop Core Services</li> <li>Testing Toolkit (TTK)</li> <li>Two DFSP simulators (payer &amp; payee)</li> <li>DFSP onboarding</li> <li>P2P transfer simulation</li> </ul> <p>\u26a0\ufe0f This environment is for development and testing only.</p>"},{"location":"deploy-mojaloop-local-microk8s/#system-requirements","title":"\ud83d\udda5\ufe0f System Requirements","text":"<p>Minimum:</p> <ul> <li>Ubuntu 24.04 LTS</li> <li>16GB RAM (32GB recommended)</li> <li>4+ CPU cores</li> <li>50GB disk</li> <li>sudo privileges</li> </ul> <p>Verify Ubuntu version:</p> <pre><code>lsb_release -a\n</code></pre>"},{"location":"deploy-mojaloop-local-microk8s/#1-install-microk8s","title":"1\ufe0f\u20e3 Install MicroK8s","text":"<pre><code>sudo snap install microk8s --classic --channel=1.31/stable\n</code></pre> <p>Add your user:</p> <pre><code>sudo usermod -a -G microk8s $USER\nnewgrp microk8s\n</code></pre> <p>Verify:</p> <pre><code>microk8s status --wait-ready\n</code></pre>"},{"location":"deploy-mojaloop-local-microk8s/#2-enable-required-add-ons","title":"2\ufe0f\u20e3 Enable Required Add-ons","text":"<pre><code>microk8s enable dns\nmicrok8s enable ingress\nmicrok8s enable storage\nmicrok8s enable helm3\n</code></pre> <p>Alias kubectl:</p> <pre><code>echo \"alias kubectl='microk8s kubectl'\" &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>"},{"location":"deploy-mojaloop-local-microk8s/#3-add-helm-repositories","title":"3\ufe0f\u20e3 Add Helm Repositories","text":"<pre><code>helm repo add bitnami https://charts.bitnami.com/bitnami\nhelm repo add elastic https://helm.elastic.co\nhelm repo add mojaloop https://mojaloop.io/helm/repo/\nhelm repo update\n</code></pre>"},{"location":"deploy-mojaloop-local-microk8s/#4-deploy-mojaloop-backend","title":"4\ufe0f\u20e3 Deploy Mojaloop Backend","text":"<pre><code>helm install backend mojaloop/example-mojaloop-backend \\\n  --namespace mojaloop \\\n  --create-namespace\n</code></pre> <p>Wait for pods:</p> <pre><code>kubectl get pods -n mojaloop\n</code></pre>"},{"location":"deploy-mojaloop-local-microk8s/#5-deploy-mojaloop-core","title":"5\ufe0f\u20e3 Deploy Mojaloop Core","text":"<pre><code>helm install dev mojaloop/mojaloop \\\n  --namespace mojaloop\n</code></pre> <p>Verify:</p> <pre><code>kubectl get pods -n mojaloop\n</code></pre>"},{"location":"deploy-mojaloop-local-microk8s/#6-configure-local-dns","title":"6\ufe0f\u20e3 Configure Local DNS","text":"<p>Edit:</p> <pre><code>sudo nano /etc/hosts\n</code></pre> <p>Add:</p> <pre><code>127.0.0.1 testing-toolkit.local\n127.0.0.1 testing-toolkit.payer\n127.0.0.1 testing-toolkit.payee\n127.0.0.1 mojaloop.local\n</code></pre>"},{"location":"deploy-mojaloop-local-microk8s/#7-deploy-dfsp-1-payer","title":"7\ufe0f\u20e3 Deploy DFSP 1 \u2014 Payer","text":""},{"location":"deploy-mojaloop-local-microk8s/#create-namespace","title":"Create Namespace","text":"<pre><code>kubectl create namespace payer\n</code></pre>"},{"location":"deploy-mojaloop-local-microk8s/#create-payer_valuesyaml","title":"Create payer_values.yaml","text":"<pre><code>touch payer_values.yaml\nnano payer_values.yaml\n</code></pre> <p>Add:</p> <pre><code>global:\n  fspId: payer\n\nconfig:\n  mojaloop:\n    endpoint: http://dev-ml-api-adapter-service.mojaloop:3000\n  callback:\n    endpoint: http://payer-ml-testing-toolkit-backend.payer:4040\n\ningress:\n  enabled: true\n  hosts:\n    - host: testing-toolkit.payer\n      paths:\n        - /\n</code></pre>"},{"location":"deploy-mojaloop-local-microk8s/#deploy","title":"Deploy","text":"<pre><code>helm install payer mojaloop/ml-testing-toolkit \\\n  --namespace payer \\\n  -f payer_values.yaml\n</code></pre> <p>Verify:</p> <pre><code>kubectl get pods -n payer\n</code></pre> <p>Access:</p> <pre><code>http://testing-toolkit.payer\n</code></pre>"},{"location":"deploy-mojaloop-local-microk8s/#8-deploy-dfsp-2-payee","title":"8\ufe0f\u20e3 Deploy DFSP 2 \u2014 Payee","text":"<pre><code>kubectl create namespace payee\ntouch payee_values.yaml\nnano payee_values.yaml\n</code></pre> <p>Add:</p> <pre><code>global:\n  fspId: payee\n\nconfig:\n  mojaloop:\n    endpoint: http://dev-ml-api-adapter-service.mojaloop:3000\n  callback:\n    endpoint: http://payee-ml-testing-toolkit-backend.payee:4040\n\ningress:\n  enabled: true\n  hosts:\n    - host: testing-toolkit.payee\n      paths:\n        - /\n</code></pre> <p>Deploy:</p> <pre><code>helm install payee mojaloop/ml-testing-toolkit \\\n  --namespace payee \\\n  -f payee_values.yaml\n</code></pre> <p>Access:</p> <pre><code>http://testing-toolkit.payee\n</code></pre>"},{"location":"deploy-mojaloop-local-microk8s/#9-dfsp-onboarding","title":"9\ufe0f\u20e3 DFSP Onboarding","text":"<ol> <li>Open <code>http://testing-toolkit.local</code></li> <li>Go to Test Runner</li> <li>Import collections from:</li> </ol> <pre><code>https://github.com/mojaloop/testing-toolkit-test-cases\n</code></pre> <p>Run:</p> <pre><code>https://github.com/mojaloop/testing-toolkit-test-cases/blob/master/collections/hub/provisioning/new_hub/new_hub.json\nhttps://github.com/mojaloop/testing-toolkit-test-cases/blob/master/collections/hub/provisioning/new_participants/new_dfsp.json\n</code></pre> <ul> <li>new_hub.json  (for hub)</li> <li>new_dfsp.json (for payer)</li> <li>new_dfsp.json (for payee)</li> </ul> <p>Update callback URLs per namespace.</p>"},{"location":"deploy-mojaloop-local-microk8s/#simulate-p2p-transfer","title":"\ud83d\udd1f Simulate P2P Transfer","text":"<p>From payer TTK:</p> <ol> <li>Load:</li> </ol> <pre><code>p2ptransfer/collections/p2p_happy_path.json\n</code></pre> <ol> <li>Load environment:</li> </ol> <pre><code>p2ptransfer/envs/p2p_happy_path_env.json\n</code></pre> <ol> <li>Click Run</li> </ol> <p>Monitor payee TTK \u2192 Monitoring</p> <p>You should observe:</p> <ul> <li>GET /parties</li> <li>POST /quotes</li> <li>POST /transfers</li> </ul>"},{"location":"deploy-mojaloop-local-microk8s/#cleanup","title":"\ud83e\uddf9 Cleanup","text":"<pre><code>helm uninstall dev -n mojaloop\nhelm uninstall backend -n mojaloop\nkubectl delete namespace mojaloop payer payee pm4ml\n</code></pre>"},{"location":"deploy-mojaloop-local-microk8s/#summary","title":"\u2705 Summary","text":"<p>You now have a full local Mojaloop environment including:</p> <ul> <li>MicroK8s Kubernetes</li> <li>Mojaloop core</li> <li>Two DFSP simulators</li> <li>DFSP onboarding</li> <li>P2P transfer simulation</li> </ul> <p>This environment can be used for:</p> <ul> <li>DFSP development</li> <li>Integration testing</li> <li>Architecture learning</li> </ul>"},{"location":"deploy-mojaloop-local-microk8s/#references","title":"\ud83d\udcda References","text":"<p>This guide is aligned with the official Mojaloop documentation:</p> <ul> <li>Mojaloop Helm Charts Repository</li> <li>Mojaloop Deployment Guide (Legacy)</li> </ul>"},{"location":"deploy-mojaloop-local-withoutk8s/","title":"Local Deployment Guide on Mojaloop Platform Components","text":"<p>This document reflects the local non-Kubernetes deployment maintained under Project:</p> <p>\ud83d\udc49 Mojaloop Local Deployment Repository</p> <p>\u26a0\ufe0f Scope Notice</p> <p>This deployment guide is intended for local development, testing, and learning purposes only.  It is not production-hardened and does not include:</p> <ul> <li>High availability (HA)</li> <li>Horizontal scaling</li> <li>TLS/mTLS enforcement</li> <li>Network isolation</li> <li>Observability stack (Prometheus, Grafana, etc.)</li> </ul> <p>For production deployments, refer to the Platform Architecture and Security Architecture documentation.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#introduction","title":"Introduction","text":"<p>Mojaloop is an open-source platform that provides interoperable digital payment infrastructure. It was created by the Mojaloop Foundation to address the challenge of siloed payment systems that limit financial inclusion, particularly in emerging markets and underbanked regions. By offering a set of open standards and software, Mojaloop enables different financial service providers (FSPs) to connect and transact seamlessly \u2014 lowering costs and expanding access to digital financial services.</p> <p>This repository, which is part of Project MELODY, provides a guide and configuration for deploying Mojaloop's core platform services locally, without Kubernetes or Helm. It is intended for development, testing, and learning purposes.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#platform-components","title":"Platform Components","text":"<p>The core Mojaloop services included in this deployment are located in the <code>platform/</code> folder. Each subfolder contains the source for a specific version/tag of the component.</p> Component Version Description account-lookup-service <code>17.14.4</code> Handles participant discovery and routing. Maintains a registry of FSPs and their endpoints so the switch can locate the correct recipient institution for a payment. quoting-service <code>17.13.8</code> Calculates fees and FSP commissions for interoperable transactions, giving both payer and payee FSPs a complete view of all costs involved. central-ledger <code>19.11.3</code> The core ledger that manages transfers between participating institutions. Provides real-time clearing messages, maintains account positions, and handles scheme-level fees. central-settlement <code>17.2.6</code> Manages settlement between FSPs and the central hub. Administers settlement windows, event triggers, and FSP account details. ml-api-adapter <code>16.6.1</code> A translation layer that converts between the Mojaloop API and the internal format used by the Central Services stack. sdk-scheme-adapter <code>0.0.70</code> Bridges non-Mojaloop-compliant DFSP backends with the Mojaloop switch by translating synchronous HTTP calls into native Mojaloop API interactions."},{"location":"deploy-mojaloop-local-withoutk8s/#infrastructure-tools","title":"Infrastructure Tools","text":"<p>Mojaloop's platform services depend on several infrastructure tools. Configuration and scripts for each are provided in the <code>tools/</code> folder.</p> Tool Folder Purpose Apache Kafka <code>tools/kafka/</code> Message broker for asynchronous event streaming between services. Redis <code>tools/redis/</code> In-memory data store used as a distributed cache (runs as a 6-node cluster). MySQL <code>tools/mysql/</code> Relational database for central-ledger, quoting-service, and account-lookup-service. Redpanda <code>tools/redpanda/</code> Kafka-compatible streaming platform (alternative to Apache Kafka)."},{"location":"deploy-mojaloop-local-withoutk8s/#additional-tools","title":"Additional Tools","text":"Tool Folder Purpose Postman <code>tools/postman/</code> API collection (<code>Melody.postman_collection.json</code>) for testing Mojaloop endpoints. JMeter <code>tools/jmeter/</code> Performance/load testing scripts for wallet-to-wallet transfers."},{"location":"deploy-mojaloop-local-withoutk8s/#setup-guide","title":"Setup Guide","text":""},{"location":"deploy-mojaloop-local-withoutk8s/#1-kafka","title":"1. Kafka","text":"<p>Mojaloop uses Apache Kafka (in KRaft mode \u2014 no ZooKeeper) for event streaming between services. Download Kafka from https://dlcdn.apache.org/kafka/3.9.1/kafka_2.12-3.9.1.tgz.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#11-configure","title":"1.1 Configure","text":"<p>Copy the provided <code>server.properties</code> into your Kafka installation:</p> <pre><code>cp tools/kafka/server.properties &lt;KAFKA_HOME&gt;/config/server.properties\n</code></pre> <p>Key settings in the provided configuration:</p> Setting Value Notes <code>process.roles</code> <code>broker,controller</code> Runs in KRaft mode (combined broker + controller) <code>listeners</code> <code>INTERNAL://0.0.0.0:9092, EXTERNAL://0.0.0.0:9094, CONTROLLER://localhost:9093</code> Internal for local services, External for Docker containers <code>advertised.listeners</code> <code>INTERNAL://localhost:9092, EXTERNAL://host.docker.internal:9094</code> Docker services connect via <code>host.docker.internal:9094</code> <code>log.dirs</code> <code>/home/mojaloop/storage</code> Update this to your preferred data directory"},{"location":"deploy-mojaloop-local-withoutk8s/#12-initialize-and-start","title":"1.2 Initialize and Start","text":"<pre><code># From your Kafka installation directory:\n\n# Initialize the storage (first time only)\n./tools/kafka/scripts/init-kafka.sh\n\n# Start the broker\n./tools/kafka/scripts/start-kafka.sh\n</code></pre>"},{"location":"deploy-mojaloop-local-withoutk8s/#13-create-topics","title":"1.3 Create Topics","text":"<p>Mojaloop requires a set of predefined Kafka topics. Create them with:</p> <pre><code>./tools/kafka/scripts/create-topics.sh [KAFKA_HOST] [KAFKA_PORT]\n# Defaults to localhost:9092 if no arguments given\n</code></pre> <p>This creates the following topics (replication-factor=1, partitions=1):</p> Category Topics Transfers <code>topic-transfer-prepare</code>, <code>topic-transfer-position</code>, <code>topic-transfer-fulfil</code>, <code>topic-transfer-get</code>, <code>topic-transfer-position-batch</code> Admin <code>topic-admin-transfer</code> Notifications <code>topic-notification-event</code> Bulk <code>topic-bulk-prepare</code>, <code>topic-bulk-fulfil</code>, <code>topic-bulk-processing</code>, <code>topic-bulk-get</code> Quotes <code>topic-quotes-post</code>, <code>topic-quotes-put</code>, <code>topic-quotes-get</code> FX Quotes <code>topic-fx-quotes-post</code>, <code>topic-fx-quotes-put</code>, <code>topic-fx-quotes-get</code> Bulk Quotes <code>topic-bulkquotes-post</code>, <code>topic-bulkquotes-put</code>, <code>topic-bulkquotes-get</code> Settlement <code>topic-deferredsettlement-close</code>"},{"location":"deploy-mojaloop-local-withoutk8s/#14-utility-scripts","title":"1.4 Utility Scripts","text":"Script Purpose <code>tools/kafka/scripts/list-group-details.sh</code> Lists consumer group lag and offsets for all Mojaloop consumer groups <code>tools/kafka/scripts/remove-all-topics.sh</code> Deletes all non-internal topics (useful for a clean reset)"},{"location":"deploy-mojaloop-local-withoutk8s/#15-redpanda-console-optional","title":"1.5 Redpanda Console (Optional)","text":"<p>For a web UI to inspect Kafka topics, consumer groups, and messages, you can run the Redpanda Console:</p> <pre><code>docker compose -f tools/redpanda/docker-compose.yml up -d\n</code></pre> <p>The console will be available at http://localhost:18080. It connects to Kafka via <code>host.docker.internal:9094</code> (the EXTERNAL listener).</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#2-redis-cluster","title":"2. Redis Cluster","text":"<p>Mojaloop uses a Redis cluster as a distributed cache. The provided script sets up a 3-node cluster locally.</p> <p>Prerequisites: Redis 7 must be installed. Ensure <code>redis-server</code> and <code>redis-cli</code> are available on your <code>PATH</code>.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#21-start-the-cluster","title":"2.1 Start the Cluster","text":"<pre><code>cd tools/redis\n./start-redis-cluster.sh\n</code></pre> <p>This will: 1. Create a <code>redis-cluster/</code> directory with per-node configuration and data 2. Start 3 Redis instances on ports 6379, 6380, and 6381 3. Form them into a cluster with <code>--cluster-replicas 0</code> (no replicas, masters only)</p> <p>Each node runs with <code>cluster-enabled yes</code>, <code>appendonly yes</code>, and <code>protected-mode no</code>.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#22-stop-the-cluster","title":"2.2 Stop the Cluster","text":"<pre><code>cd tools/redis\n./stop-redis-cluster.sh\n</code></pre> <p>This shuts down all 3 nodes (ports 6379\u20136381) gracefully.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#3-mysql","title":"3. MySQL","text":"<p>Mojaloop's central-ledger, quoting-service, and account-lookup-service store data in MySQL. Version 8.4 or lower is supported (Mojaloop recommends 5.7).</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#31-configure","title":"3.1 Configure","text":"<p>Use the provided <code>my.cnf</code> as a template:</p> <pre><code>[mysqld]\nbasedir=/&lt;your_mysql_location&gt;\ndatadir=/&lt;your_mysql_location&gt;/data\nsocket=/tmp/mysql.sock\nport=3306\nmysql_native_password=ON\n</code></pre> <p>Important: If using MySQL 8.4+, the <code>mysql_native_password=ON</code> setting is required because Mojaloop's database libraries rely on the <code>mysql_native_password</code> authentication plugin.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#32-create-the-database-user","title":"3.2 Create the Database User","text":"<pre><code>-- Create the user (or alter if it already exists)\nALTER USER 'central_ledger'@'%' IDENTIFIED WITH mysql_native_password BY 'password';\n\n-- Grant full privileges (required for Knex DB migrations)\nGRANT ALL PRIVILEGES ON *.* TO 'central_ledger'@'%';\nFLUSH PRIVILEGES;\n</code></pre> <p><code>central_ledger</code> is the default username used by Mojaloop services. You can change it, but you will need to update the service configurations accordingly.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#4-running-platform-services","title":"4. Running Platform Services","text":"<p>Prerequisites: Ensure Kafka, Redis, and MySQL are running before starting any platform service.</p> <p>Each service is pre-configured with a <code>default.json</code> that points to the local infrastructure tools (Kafka at <code>localhost:9092</code>, Redis at <code>localhost:6379</code>, MySQL at <code>localhost:3306</code>). If you are using the same settings from the setup steps above, no configuration changes are needed.</p> <p>Services should be started in the following order:</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#41-central-ledger","title":"4.1 Central Ledger","text":"<p>The central-ledger is the core service and must be started first, as other services depend on it.</p> <pre><code>cd platform/central-ledger-19.11.3\nnpm install\nnpm run start:api\n</code></pre> Setting Value API Port <code>3001</code> MySQL User / Schema <code>central_ledger</code> / <code>central_ledger</code> Config <code>platform/central-ledger-19.11.3/config/default.json</code> <p>On first run, Knex will automatically run database migrations (<code>MIGRATIONS.DISABLED: false</code>).</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#42-account-lookup-service","title":"4.2 Account Lookup Service","text":"<pre><code>cd platform/account-lookup-service-17.14.4\nnpm install\nnpm run start:all\n</code></pre> Setting Value Admin Port <code>4001</code> API Port <code>4002</code> Monitoring Port <code>4003</code> MySQL User / Schema <code>account_lookup</code> / <code>account_lookup</code> Config <code>platform/account-lookup-service-17.14.4/config/default.json</code> <p>This service uses a separate MySQL user (<code>account_lookup</code>). Make sure to create it the same way as <code>central_ledger</code> (see Section 3.2).</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#43-quoting-service-api","title":"4.3 Quoting Service (API)","text":"<pre><code>cd platform/quoting-service-17.13.8\nnpm install\nnpm run start:api\n</code></pre> Setting Value API Port <code>3002</code> Monitoring Port <code>3003</code> MySQL User / Schema <code>central_ledger</code> / <code>central_ledger</code> Config <code>platform/quoting-service-17.13.8/config/default.json</code>"},{"location":"deploy-mojaloop-local-withoutk8s/#44-quoting-service-handlers","title":"4.4 Quoting Service (Handlers)","text":"<p>In a separate terminal, start the Kafka consumer handlers for the quoting service:</p> <pre><code>cd platform/quoting-service-17.13.8\nnpm run start:handlers\n</code></pre> <p>The handlers consume from Kafka topics (<code>topic-quotes-*</code>, <code>topic-bulkquotes-*</code>, <code>topic-fx-quotes-*</code>) and process quote requests asynchronously. <code>npm install</code> is not needed again if already done in step 4.3.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#45-ml-api-adapter","title":"4.5 ML API Adapter","text":"<pre><code>cd platform/ml-api-adapter-16.6.1\nnpm install\nnpm run start:api\n</code></pre> Setting Value API Port <code>3000</code> Central Ledger Endpoint <code>http://localhost:3001</code> Config <code>platform/ml-api-adapter-16.6.1/config/default.json</code> <p>This is the main entry point for FSPIOP API calls. It forwards transfer requests to the central-ledger via Kafka.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#46-central-settlement","title":"4.6 Central Settlement","text":"<pre><code>cd platform/central-settlement-17.2.6\nnpm install\nnpm run start:api\n</code></pre> Setting Value API Port <code>3007</code> MySQL User / Schema <code>central_ledger</code> / <code>central_ledger</code> Central Ledger Endpoint <code>http://localhost:3001</code> Config <code>platform/central-settlement-17.2.6/config/default.json</code>"},{"location":"deploy-mojaloop-local-withoutk8s/#5-building-and-running-the-simulator","title":"5. Building and Running the Simulator","text":"<p>The simulator provides two wallet instances (wallet1 and wallet2) that act as DFSPs, allowing you to test end-to-end transfers through the Mojaloop platform.</p> <p>The simulator's Connector component is production-grade and can be used as the foundation for connecting your FSP to Mojaloop. It reduces one network hop compared to the standard approach:</p> Approach Flow Hops to Hub Connector (recommended) FSP \u2192 Connector \u2192 Hub 2 sdk-scheme-adapter FSP \u2192 Core Connector \u2192 sdk-scheme-adapter \u2192 Hub 3 <p>Both approaches work, but if you want a leaner integration, the Connector provides a more direct path. Alternatively, you can use the sdk-scheme-adapter with a Core Connector if that better suits your architecture.</p> <p>Note: If you need ready-made features such as mTLS, transaction logging, and a management portal, consider using PM4ML (Payment Manager for Mojaloop), which already bundles a Core Connector and sdk-scheme-adapter out of the box.</p> <p>Prerequisites: Apache Maven and JDK 21 (or 25) must be installed.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#51-build-the-simulator","title":"5.1 Build the Simulator","text":"<pre><code>cd simulator\nmvn install -DskipTests=true\n</code></pre>"},{"location":"deploy-mojaloop-local-withoutk8s/#52-prepare-the-wallets","title":"5.2 Prepare the Wallets","text":"<p>After the build completes, copy the connector JAR and its dependencies into the <code>wallets/</code> folder:</p> <pre><code>mkdir -p wallets/lib\ncp simulator/connector/target/mod_connector-1.0.0.jar wallets/\ncp simulator/connector/target/lib/* wallets/lib/\n</code></pre> <p>Your <code>wallets/</code> folder should look like this:</p> <pre><code>wallets/\n\u251c\u2500\u2500 mod_connector-1.0.0.jar\n\u251c\u2500\u2500 lib/                          # dependency JARs\n\u251c\u2500\u2500 wallet1.sh\n\u251c\u2500\u2500 wallet1-log4j2.xml\n\u251c\u2500\u2500 wallet2.sh\n\u2514\u2500\u2500 wallet2-log4j2.xml\n</code></pre>"},{"location":"deploy-mojaloop-local-withoutk8s/#53-run-the-wallets","title":"5.3 Run the Wallets","text":"<p>Start each wallet in a separate terminal:</p> <pre><code># Terminal 1 \u2014 Wallet 1\ncd wallets\n./wallet1.sh\n</code></pre> <pre><code># Terminal 2 \u2014 Wallet 2\ncd wallets\n./wallet2.sh\n</code></pre> Wallet FSP ID Inbound Port Outbound Port Wallet 1 <code>wallet1</code> <code>8081</code> <code>8080</code> Wallet 2 <code>wallet2</code> <code>9091</code> <code>9090</code> <p>Both wallets connect to the platform services at their default local ports (account-lookup on <code>4002</code>, quoting-service on <code>3002</code>, ml-api-adapter on <code>3000</code>).</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#6-onboarding-wallets","title":"6. Onboarding Wallets","text":"<p>Once all platform services and wallets are running, you need to onboard the wallets (DFSPs) onto the Mojaloop hub. This is done using the Postman collection at <code>tools/postman/Melody.postman_collection.json</code>.</p> <p>Prerequisites: Import the collection into Postman.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#61-setup-the-hub","title":"6.1 Setup the Hub","text":"<p>Open the onboarding &gt; create-hub folder in the Postman collection and run each request in order:</p> <ol> <li><code>list enums</code> \u2014 verify the hub is reachable</li> <li><code>setup-HUB_MULTILATERAL_SETTLEMENT</code> \u2014 create the multilateral settlement account</li> <li><code>setup-HUB_RECONCILIATION</code> \u2014 create the reconciliation account</li> <li><code>create settlement model</code> \u2014 configure the settlement model</li> <li><code>add Oracle</code> (optional) \u2014 register the an oracle for party lookups. Skip this if you do not have Oracle.</li> <li><code>get Oracles</code> (optional) \u2014 verify the oracle was registered</li> </ol>"},{"location":"deploy-mojaloop-local-withoutk8s/#62-create-participants","title":"6.2 Create Participants","text":"<p>Open the onboarding &gt; create-participants folder. Run the requests for wallet1 and wallet2 (steps 1\u20134 in order):</p> <p>For each wallet:</p> Step Request Purpose 1 <code>create new participant</code> Register the DFSP with the hub 2 <code>activate POSITION account</code> Activate the position account 3 <code>create limit and position</code> Set the Net Debit Cap (NDC) limit 4 <code>fund In to SETTLEMENT account</code> Fund the settlement account <p>After creating participants, proceed to Section 6.3 to register the callback endpoints for wallet1 and wallet2.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#63-register-wallet-endpoints","title":"6.3 Register Wallet Endpoints","text":"<p>After completing the Postman steps above, run the endpoint registration scripts to register all FSPIOP callback URLs for each wallet:</p> <pre><code>./onboarding/register-wallet1-endpoints.sh\n./onboarding/register-wallet2-endpoints.sh\n</code></pre> <p>These scripts register callback endpoints (parties, quotes, transfers, bulk operations, etc.) against the central-ledger, pointing to each wallet's outbound port:</p> Wallet Callback Base URL Wallet 1 <code>http://localhost:8080</code> Wallet 2 <code>http://localhost:9090</code> <p>After this step, both wallets are fully onboarded and ready to send/receive transfers through the Mojaloop platform.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#7-performing-transfers","title":"7. Performing Transfers","text":"<p>With all services running and wallets onboarded, you can perform end-to-end transfers using Apache JMeter.</p> <p>Prerequisites: JDK 21 (or 25) and Apache JMeter 5.6.3 must be installed.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#71-run-a-transfer-test","title":"7.1 Run a Transfer Test","text":"<ol> <li>Open Apache JMeter</li> <li>Load the test plan: File &gt; Open \u2192 <code>tools/jmeter/wallet1-to-wallet2.jmx</code></li> <li>Click the Start button (\u25b6) to run the test</li> </ol> <p>The test plan sends transfers from wallet1 to wallet2 through the full Mojaloop flow (party lookup \u2192 quote \u2192 transfer). By default it runs with 1 thread and 100 iterations.</p> Setting Value Payer FSP <code>wallet1</code> Payee FSP <code>wallet2</code> Target <code>http://localhost:8081</code> (wallet1 inbound) Threads <code>1</code> Loop Count <code>100</code> <p>A reverse test plan (<code>wallet2-to-wallet1.jmx</code>) is also available in the same folder for testing transfers in the opposite direction.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#8-settlement","title":"8. Settlement","text":"<p>After performing transfers, you can settle the net positions between participants. The settlement process is available in the Postman collection under the settlement folder.</p> <p>Follow these steps in order:</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#81-close-the-current-settlement-window","title":"8.1 Close the Current Settlement Window","text":"<p>Close the currently open settlement window so that all completed transfers are captured for settlement.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#82-create-the-settlement","title":"8.2 Create the Settlement","text":"<p>Create a new settlement to calculate the net amounts to be settled between participants. This will show how much each FSP owes or is owed based on the transfers that occurred within the closed window.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#83-update-the-settlement-status","title":"8.3 Update the Settlement Status","text":"<p>Update the settlement status to progress it through the settlement lifecycle (e.g., from <code>PENDING_SETTLEMENT</code> to <code>PS_TRANSFERS_RECORDED</code> to <code>PS_TRANSFERS_COMMITTED</code>).</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#84-deposit-or-withdraw-funds","title":"8.4 Deposit or Withdraw Funds","text":"<p>Based on the net settlement amounts from step 8.2: - Deposit funds into the settlement account for FSPs that owe money (net debtors) - Withdraw funds from the settlement account for FSPs that are owed money (net creditors)</p> <p>This final step reconciles the actual fund movements and completes the settlement cycle.</p>"},{"location":"deploy-mojaloop-local-withoutk8s/#port-summary","title":"Port Summary","text":"Service Port(s) ml-api-adapter <code>3000</code> central-ledger <code>3001</code> quoting-service (API) <code>3002</code> quoting-service (Monitoring) <code>3003</code> central-settlement <code>3007</code> account-lookup-service (Admin) <code>4001</code> account-lookup-service (API) <code>4002</code> account-lookup-service (Monitoring) <code>4003</code> Wallet 1 (Inbound / Outbound) <code>8081</code> / <code>8080</code> Wallet 2 (Inbound / Outbound) <code>9091</code> / <code>9090</code>"},{"location":"deploy-payment-manager-on-premise/","title":"Payment Manager for Mojaloop (PM4ML)","text":""},{"location":"deploy-payment-manager-on-premise/#on-premise-deployment-environment-architecture-guide","title":"On-Premise Deployment &amp; Environment Architecture Guide","text":"<p>This document provides step-by-step guidance for deploying Payment Manager for Mojaloop (PM4ML) in an on-premise data center environment using:</p> <ul> <li>Ubuntu 24.04 LTS</li> <li>MicroK8s (Kubernetes)</li> <li>Ansible</li> <li>GitOps with Argo CD</li> <li>HAProxy (External &amp; Internal Load Balancer)</li> <li>WireGuard VPN (Optional)</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#code-base-reference","title":"Code Base Reference","text":"<p>This deployment architecture is derived from the official Mojaloop Infrastructure as Code (IaC) modules:</p> <ul> <li>Mojaloop IaC Modules: https://github.com/mojaloop/iac-modules</li> </ul> <p>The original AWS-focused implementation has been adapted and extended to support on-premise infrastructure using MicroK8s, HAProxy, and GitOps-based workflows.</p>"},{"location":"deploy-payment-manager-on-premise/#pm4ml-on-premise-architecture-overview","title":"PM4ML On-Premise Architecture Overview","text":"<p>The following diagram illustrates the logical and network architecture of the PM4ML on-premise deployment.</p>"},{"location":"deploy-payment-manager-on-premise/#logical-architecture-view","title":"Logical Architecture View","text":""},{"location":"deploy-payment-manager-on-premise/#network-architecture-view","title":"Network Architecture View","text":""},{"location":"deploy-payment-manager-on-premise/#1-prerequisites","title":"1. Prerequisites","text":""},{"location":"deploy-payment-manager-on-premise/#11-infrastructure-requirements-production-recommended","title":"1.1 Infrastructure Requirements (Production Recommended)","text":"Component Count Purpose HAProxy 1\u20132 Public &amp; Private ingress load balancer MicroK8s Master Nodes 3 Kubernetes control plane Worker Nodes 3+ Application workloads Storage Servers (Ceph) 3+ Distributed storage cluster"},{"location":"deploy-payment-manager-on-premise/#12-network-requirements","title":"1.2 Network Requirements","text":"<ul> <li>Static IP address for each VM  </li> <li>Dedicated internal subnet (e.g., <code>10.10.0.0/16</code>)  </li> <li>Public IP mapped to HAProxy via firewall or edge device  </li> <li>DNS zone (AWS Route53, Cloudflare, or enterprise DNS)  </li> </ul>"},{"location":"deploy-payment-manager-on-premise/#13-network-port-requirements","title":"1.3 Network Port Requirements","text":""},{"location":"deploy-payment-manager-on-premise/#131-public-network-external-access","title":"1.3.1 Public Network (External Access)","text":"<p>Ports exposed to the internet or external partners.</p> Port Protocol Purpose Notes 22 TCP SSH Restricted by IP whitelist 80 TCP HTTP Redirect to HTTPS 443 TCP HTTPS Public API / Portal 51820 UDP WireGuard VPN If WireGuard VPN is enabled <p>Replace the WireGuard port with the actual port configured on your firewall or edge device (e.g., FortiGate, F5, or equivalent).</p>"},{"location":"deploy-payment-manager-on-premise/#132-private-network-internal-communication","title":"1.3.2 Private Network (Internal Communication)","text":"<p>Ports used for internal cluster, storage, and load balancer communication. These ports must not be exposed publicly.</p>"},{"location":"deploy-payment-manager-on-premise/#microk8s-kubernetes-cluster","title":"MicroK8s (Kubernetes Cluster)","text":"Port Protocol Purpose 6443 TCP Kubernetes API Server 10250 TCP Kubelet 25000 TCP MicroK8s Cluster Agent 12379-12380 TCP etcd (MicroK8s datastore)"},{"location":"deploy-payment-manager-on-premise/#istio-ingress-gateways-nodeport","title":"Istio Ingress Gateways (NodePort)","text":"<p>HAProxy forwards traffic to Kubernetes nodes via NodePort services.</p> <p>External Istio Ingress Gateway</p> Port Protocol Purpose 32080 TCP HTTP (NodePort) 32443 TCP HTTPS (NodePort) 32081 TCP Status Port (15021) <p>Internal Istio Ingress Gateway</p> Port Protocol Purpose 31080 TCP HTTP (NodePort) 31443 TCP HTTPS (NodePort) 31081 TCP Status Port (15021) <p>These NodePorts must be accessible only from HAProxy source IP addresses. They must not be exposed to public networks.</p>"},{"location":"deploy-payment-manager-on-premise/#microceph-ceph-cluster","title":"MicroCeph (Ceph Cluster)","text":"Port Protocol Purpose 6789 TCP Ceph Monitor (v1) 3300 TCP Ceph Monitor (v2) 6800-7300 TCP Ceph OSD communication"},{"location":"deploy-payment-manager-on-premise/#haproxy-load-balancer","title":"HAProxy (Load Balancer)","text":"Port Protocol Purpose 80 TCP Frontend HTTP 443 TCP Frontend HTTPS 8404 TCP HAProxy statistics (if enabled)"},{"location":"deploy-payment-manager-on-premise/#internal-security-controls","title":"Internal Security Controls","text":"<ul> <li>NodePort ranges must be restricted to HAProxy source IPs only.  </li> <li>Kubernetes control-plane ports must be restricted to cluster nodes.  </li> <li>Ceph cluster traffic must remain within the private storage network.  </li> <li>No NodePort service may be directly exposed to the internet.  </li> <li>All ingress traffic must pass through HAProxy before reaching Istio.  </li> <li>TLS or mTLS must be enforced where applicable.  </li> </ul>"},{"location":"deploy-payment-manager-on-premise/#14-storage-requirements","title":"1.4 Storage Requirements","text":"<ul> <li>Ceph RBD for Kubernetes persistent volumes  </li> <li>Ceph-backed storage for logs, backups, and non-transaction-critical workloads  </li> <li>Transaction-critical databases and messaging systems should use local high-performance storage (e.g., NVMe) where required  </li> </ul>"},{"location":"deploy-payment-manager-on-premise/#2-tools-versions","title":"2. Tools &amp; Versions","text":"Tool Version Ubuntu 24.04 LTS MicroK8s 1.31/stable Ansible 2.18+ Helm v3 kubectl Matching cluster version Git Latest stable"},{"location":"deploy-payment-manager-on-premise/#3-vm-provisioning","title":"3. VM Provisioning","text":"<p>VMs may be provisioned using:</p> <ul> <li>VMware</li> <li>Proxmox</li> <li>OpenStack</li> <li>CloudStack</li> <li>Bare Metal</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#4-infrastructure-sizing-by-environment","title":"4. Infrastructure Sizing by Environment","text":""},{"location":"deploy-payment-manager-on-premise/#41-production-environment-prod","title":"4.1 Production Environment (PROD)","text":""},{"location":"deploy-payment-manager-on-premise/#recommended-production-infrastructure-sizing","title":"Recommended Production Infrastructure Sizing","text":"Component Quantity CPU / RAM / Storage (Per Server) Deployment Type Notes Master Node Cluster \u00d73 Servers 8 CPU Cores, 32 GB RAM, 2 \u00d7 300 GB NVMe VM Dedicated control plane nodes Worker Node Cluster \u00d73 Servers 16 CPU Cores, 64 GB RAM, 2 \u00d7 500 GB NVMe VM Application workloads only Load Balancers (HAProxy) \u00d72 Servers 4 CPU Cores, 16 GB RAM, 100 GB SSD VM Active/Active or Active/Standby Cold Data Storage Cluster \u00d73 Servers 16 CPU Cores, 64 GB RAM; OS: 2 \u00d7 500 GB SSD (RAID1); Data: 6 \u00d7 8 TB HDD; Network: 2 \u00d7 10 Gbps Physical Recommended enterprise-grade storage Cold Data Storage Cluster (Alternative) \u00d73 VMs 16 vCPU, 64 GB RAM; OS: 200 GB SSD; Data: 20\u201340 TB dedicated enterprise block storage VM Must match physical capacity &amp; IOPS SLA Bastion Host (Optional) \u00d71 Server 2 CPU Cores, 8 GB RAM, 50 GB SSD VM Secure administrative access Backup Target \u00d71 Enterprise backup system External Off-site backup retention"},{"location":"deploy-payment-manager-on-premise/#cold-storage-purpose","title":"Cold Storage Purpose","text":"<p>Cold storage infrastructure is designated exclusively for:</p> <ul> <li>Long-term regulatory record retention  </li> <li>Backup archives  </li> <li>Ledger export snapshots  </li> <li>Log archival storage  </li> </ul> <p>Cold storage must not be used for:</p> <ul> <li>Latency-sensitive transaction processing  </li> <li>Real-time database workloads  </li> <li>Messaging systems or performance-critical services  </li> </ul> <p>This separation ensures optimal transaction performance while meeting regulatory compliance and retention requirements.</p>"},{"location":"deploy-payment-manager-on-premise/#vm-based-cold-storage-considerations","title":"VM-Based Cold Storage Considerations","text":"<p>If cold storage is deployed using virtual machines instead of physical servers, the following conditions must be met:</p> <ul> <li>Underlying storage must be enterprise-grade (SAN, NAS, or dedicated block storage)</li> <li>Storage must not be oversubscribed</li> <li>IOPS and throughput guarantees must be documented</li> <li>Network bandwidth must be sufficient (minimum 10 Gbps recommended)</li> <li>Backup and redundancy policies must match physical deployment standards</li> </ul> <p>VM-based cold storage is acceptable only when the virtualization platform provides guaranteed performance and isolation equivalent to dedicated physical storage.</p>"},{"location":"deploy-payment-manager-on-premise/#42-staging-environment-stg","title":"4.2 Staging Environment (STG)","text":"<p>Designed for:</p> <ul> <li>Functional testing</li> <li>Integration testing</li> <li>Performance validation</li> <li>Pre-production validation</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#recommended-staging-infrastructure-sizing","title":"Recommended Staging Infrastructure Sizing","text":"Component Quantity CPU / RAM / Storage (Per Server) Deployment Type Notes Master + Worker Cluster \u00d72 Servers 8 CPU Cores, 16-32 GB RAM, 500 GB SSD VM Combined control plane &amp; workloads Load Balancer (HAProxy) \u00d71 Server 2 CPU Cores, 4 GB RAM, 100 GB SSD VM Single instance Cold Data Storage \u00d71 Server 8 CPU Cores, 32 GB RAM; OS: 200 GB SSD; Data: 2 \u00d7 2 TB HDD VM or Physical Reduced retention, non-production logs"},{"location":"deploy-payment-manager-on-premise/#43-environment-policy","title":"4.3 Environment Policy","text":"<ul> <li>Production must use dedicated control plane nodes</li> <li>Production must maintain high availability</li> <li>Staging may operate with reduced redundancy</li> <li>Any deviation from Production requirements must be formally approved</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#44-master-and-worker-on-same-node-risk-acceptance","title":"4.4 Master and Worker on Same Node (Risk Acceptance)","text":"<p>Combining control plane and worker workloads is technically possible but not recommended for production.</p> <p>Risks:</p> <ul> <li>Resource contention</li> <li>Reduced stability under load</li> <li>Increased blast radius</li> <li>Difficult capacity planning</li> <li>Potential Kubernetes API impact</li> </ul> <p>Production recommendation:</p> <ul> <li>3 dedicated master nodes</li> <li>Workloads only on worker nodes</li> <li>No scheduling on control plane nodes</li> </ul> <p>If combined, formal risk acceptance is required.</p>"},{"location":"deploy-payment-manager-on-premise/#5-haproxy-configuration-on-premise","title":"5. HAProxy Configuration (On-Premise)","text":""},{"location":"deploy-payment-manager-on-premise/#51-overview","title":"5.1 Overview","text":"<p>HAProxy acts as the ingress load-balancing layer in front of the MicroK8s cluster.</p> <p>Architecture:</p> <pre><code>Client \u2192 Perimeter Firewall \u2192 HAProxy \u2192 Istio Ingress Gateway \u2192 PM4ML Services\n</code></pre>"},{"location":"deploy-payment-manager-on-premise/#52-architecture-components","title":"5.2 Architecture Components","text":""},{"location":"deploy-payment-manager-on-premise/#perimeter-firewall","title":"Perimeter Firewall","text":"<ul> <li>First security boundary</li> <li>Filters inbound traffic</li> <li>May perform NAT</li> <li>Centralized logging</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#haproxy","title":"HAProxy","text":"<ul> <li>Layer 4 (TCP) load balancing</li> <li>Forwards traffic to Kubernetes nodes</li> <li>Does not terminate TLS</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#istio-ingress-gateway","title":"Istio Ingress Gateway","text":"<ul> <li>Terminates TLS</li> <li>Applies routing policies</li> <li>Enforces service mesh security</li> <li>Routes traffic to PM4ML</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#53-haproxy-interfaces","title":"5.3 HAProxy Interfaces","text":"Interface Purpose Public Receives traffic from firewall Private Forwards traffic to Kubernetes"},{"location":"deploy-payment-manager-on-premise/#54-tls-termination-strategy","title":"5.4 TLS Termination Strategy","text":"<p>TLS termination occurs at Istio Ingress Gateway.</p> <p>Benefits:</p> <ul> <li>Centralized certificate lifecycle management</li> <li>Better integration with service mesh policies</li> <li>Improved observability</li> <li>Reduced HAProxy complexity</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#55-high-availability","title":"5.5 High Availability","text":"<ul> <li>Two HAProxy nodes (Production)</li> <li>Firewall-level failover or VIP</li> <li>Separate physical hosts where possible</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#56-security-controls","title":"5.6 Security Controls","text":"<ul> <li>Expose only required ports (typically 443)</li> <li>Restrict SSH access</li> <li>Apply host-level firewall rules</li> <li>Integrate logs into monitoring/SIEM</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#57-public-and-private-ip-requirements","title":"5.7 Public and Private IP Requirements","text":""},{"location":"deploy-payment-manager-on-premise/#public-ip","title":"Public IP","text":"<ul> <li>Assigned at firewall layer</li> <li>NAT to HAProxy private IP</li> <li>Minimum: 1 Public IP</li> <li>Recommended: 1 Public VIP</li> </ul> <p>Example:</p> <pre><code>Internet \u2192 Firewall \u2192 NAT \u2192 HAProxy \u2192 Istio \u2192 Services\n</code></pre>"},{"location":"deploy-payment-manager-on-premise/#private-ip","title":"Private IP","text":"<p>Required for:</p> <ul> <li>HAProxy</li> <li>Kubernetes Masters</li> <li>Kubernetes Workers</li> <li>Storage Cluster</li> <li>Bastion Host(Optional)</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#6-gitops-deployment","title":"6. GitOps Deployment","text":"<p>The customer must provide and maintain their own Git repository for GitOps-based deployment.</p> <p>Requirements:</p> <ul> <li>Repository accessible from the cluster (HTTPS or SSH)</li> <li>Proper branch or tag strategy defined</li> <li>Secure credential/token management</li> <li>Access configured in Argo CD</li> </ul> <p>All platform manifests and Helm values must be stored in the customer's repository.</p>"},{"location":"deploy-payment-manager-on-premise/#61-platform-applications-deployment-order","title":"6.1 Platform Applications Deployment Order","text":"<p>Argo CD applications must be deployed in the following sequence to satisfy dependencies and ensure system stability.</p> <ul> <li>Base Utilities</li> <li> <p><code>base-utils</code></p> </li> <li> <p>Storage Layer</p> </li> <li> <p><code>storage-app</code></p> </li> <li> <p>Certificate Management</p> </li> <li><code>certmanager-helm</code></li> <li><code>certmanager-app</code></li> <li> <p><code>certmanager-clusterissuers</code></p> </li> <li> <p>Service Mesh</p> </li> <li><code>istio-app</code></li> <li><code>istio-main-app</code></li> <li> <p><code>istio-gateways-app</code></p> </li> <li> <p>DNS Management</p> </li> <li> <p><code>external-dns-app</code></p> </li> <li> <p>Vault Storage Backend</p> </li> <li> <p><code>consul-app</code></p> </li> <li> <p>Vault &amp; Secrets Management</p> </li> <li><code>vault-app</code></li> <li><code>vault</code></li> <li><code>vault-config-operator</code></li> <li> <p><code>vault-pki-app</code></p> </li> <li> <p>Stateful Resources</p> </li> <li><code>stateful-resources-operators-app</code></li> <li> <p><code>common-stateful-resources-app</code></p> </li> <li> <p>Monitoring Stack</p> </li> <li><code>monitoring-app</code></li> <li><code>monitoring-install</code></li> <li> <p><code>monitoring-post-config</code></p> </li> <li> <p>Identity &amp; Access Management</p> </li> <li><code>keycloak-app</code></li> <li><code>keycloak-install</code></li> <li><code>keycloak-post-config</code></li> <li> <p><code>ory-app</code></p> </li> <li> <p>PM4ML Core</p> </li> <li><code>pm4ml</code></li> </ul>"},{"location":"deploy-payment-manager-on-premise/#62-clone-repository","title":"6.2 Clone Repository","text":"<pre><code>git clone &lt;your-onprem-gitops-repo&gt;\ncd &lt;repo&gt;\n</code></pre>"},{"location":"deploy-payment-manager-on-premise/#63-pre-deployment-checklist-applications","title":"6.3 Pre-Deployment Checklist (Applications)","text":"<p>Before running <code>5.apps_setup.yml</code>, verify the following:</p>"},{"location":"deploy-payment-manager-on-premise/#configuration","title":"Configuration","text":"<ul> <li>[ ] Environment values updated (prod / staging)</li> <li>[ ] DNS hostnames updated</li> <li>[ ] Istio Gateway hosts updated</li> <li>[ ] VirtualService URLs updated</li> <li>[ ] PM4ML endpoints configured correctly</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#certificates-tls","title":"Certificates &amp; TLS","text":"<ul> <li>[ ] cert-manager Issuer / ClusterIssuer configured</li> <li>[ ] TLS secrets created or auto-generated</li> <li>[ ] DNS challenge credentials configured (if applicable)</li> <li>[ ] Certificate CN/SAN matches domain</li> <li>[ ] mTLS configuration validated (if required)</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#secrets-integrations","title":"Secrets &amp; Integrations","text":"<ul> <li>[ ] Database credentials updated</li> <li>[ ] External service credentials updated</li> <li>[ ] Vault / ExternalSecrets configuration validated</li> <li>[ ] No placeholder secrets remain</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#storage","title":"Storage","text":"<ul> <li>[ ] Correct StorageClass referenced</li> <li>[ ] PVC sizes reviewed</li> <li>[ ] Stateful workloads reference correct volumes</li> </ul>"},{"location":"deploy-payment-manager-on-premise/#resource-management","title":"Resource Management","text":"<ul> <li>[ ] CPU requests and limits defined</li> <li>[ ] Memory requests and limits defined</li> <li>[ ] HPA configuration validated (if enabled)</li> </ul> <p>Deployment must not proceed unless all checklist items are verified.</p>"},{"location":"deploy-payment-manager-on-premise/#64-run-deployment","title":"6.4 Run Deployment","text":"<p>Execute in order:</p> <pre><code>ansible-playbook -i inventory.ini 1.microk8s_setup.yml\nansible-playbook -i inventory.ini 2.argocd_setup.yml\nansible-playbook -i inventory.ini 3.haproxy_setup.yml\nansible-playbook -i inventory.ini 4.ceph.yml\nansible-playbook -i inventory.ini 5.apps_setup.yml\nansible-playbook -i inventory.ini 6.system-tuning.yml\n</code></pre>"},{"location":"deploy-payment-manager-on-premise/#65-manual-secret-hub-integrationonboarding","title":"6.5 Manual Secret (Hub Integration/Onboarding)","text":"<p>To enable PM4ML to connect with the Mojaloop Hub, create the following secret in Vault. The client secret must be obtained securely from the Mojaloop Hub operator.</p> <p>Create in Vault (KV path):</p> <pre><code>secret/&lt;pm4ml_id&gt;/\n</code></pre> <p>Key:</p> <pre><code>mcmdev_client_secret\n</code></pre>"},{"location":"deploy-payment-manager-on-premise/#66-verification","title":"6.6 Verification","text":"<pre><code>kubectl get nodes\nkubectl get app -A\n</code></pre> <p>Deployment is successful when:</p> <ul> <li>All nodes are <code>Ready</code></li> <li>Argo CD applications are <code>Synced</code> and <code>Healthy</code></li> <li>HAProxy service is <code>active</code></li> <li><code>https://argocd.&lt;domain&gt;</code> is accessible and displays the Argo CD login page</li> <li>PM4ML endpoint URLs respond with expected HTTP status codes</li> <li>Internal services are reachable from within the cluster</li> </ul>"},{"location":"hub-pm4ml-security-architecture/","title":"\ud83d\udd10 Hub \u2194 PM4ML Security Architecture","text":"<p>This document describes the actual security architecture between the Hub and PM4ML, covering mTLS (transport security) and JWS (application-level signing), based on the current PM4ML implementation.</p>"},{"location":"hub-pm4ml-security-architecture/#1-mtls-transport-level-security","title":"1. mTLS (Transport-Level Security)","text":"<p>mTLS is used to secure HTTPS communication between Hub and PM4ML. Inbound and outbound directions use different certificate lifecycles.</p>"},{"location":"hub-pm4ml-security-architecture/#2-inbound-mtls-hub-pm4ml","title":"2. Inbound mTLS (Hub \u2192 PM4ML)","text":""},{"location":"hub-pm4ml-security-architecture/#flow","title":"Flow","text":"<ul> <li>Hub initiates a connection to PM4ML</li> <li>PM4ML acts as TLS server</li> <li>PM4ML presents a server certificate</li> </ul> <pre><code>Hub \u2500\u2500mTLS\u2500\u2500\u25b6 PM4ML\n        (PM4ML server cert)\n</code></pre>"},{"location":"hub-pm4ml-security-architecture/#certificate-lifecycle","title":"Certificate lifecycle","text":"<ul> <li> <p>Certificate is:</p> </li> <li> <p>Issued by cert-manager</p> </li> <li>Backed by a Vault CA (ClusterIssuer)</li> <li>Stored as a Kubernetes <code>Secret</code></li> <li> <p>Rotation:</p> </li> <li> <p>Fully managed by cert-manager</p> </li> <li>Based on <code>duration</code> and <code>renewBefore</code></li> <li>Pods reload or restart to pick up new certs</li> </ul>"},{"location":"hub-pm4ml-security-architecture/#ownership","title":"Ownership","text":"<ul> <li>PM4ML owns and manages its server certificate</li> <li>Hub only verifies the certificate chain</li> </ul> <p>\u2714 Inbound mTLS is cert-manager\u2013managed</p>"},{"location":"hub-pm4ml-security-architecture/#3-outbound-mtls-pm4ml-hub","title":"3. Outbound mTLS (PM4ML \u2192 Hub)","text":""},{"location":"hub-pm4ml-security-architecture/#flow_1","title":"Flow","text":"<ul> <li>PM4ML initiates a connection to Hub</li> <li>PM4ML acts as TLS client</li> <li>PM4ML presents a client certificate</li> </ul> <pre><code>PM4ML \u2500\u2500mTLS\u2500\u2500\u25b6 Hub\n        (PM4ML client cert)\n</code></pre>"},{"location":"hub-pm4ml-security-architecture/#certificate-lifecycle-dfsp-trust-workflow","title":"Certificate lifecycle (DFSP trust workflow)","text":"<ul> <li> <p>PM4ML:</p> </li> <li> <p>Generates a private key + CSR</p> </li> <li>Sends CSR to Hub</li> <li> <p>Hub:</p> </li> <li> <p>Validates DFSP identity</p> </li> <li>Signs the CSR</li> <li> <p>PM4ML:</p> </li> <li> <p>Stores:</p> <ul> <li>private key</li> <li>signed certificate</li> <li>CA chain</li> <li>Storage location: Vault</li> </ul> </li> </ul>"},{"location":"hub-pm4ml-security-architecture/#rotation","title":"Rotation","text":"<ul> <li>No cert-manager involvement</li> <li> <p>Rotation is triggered by:</p> </li> <li> <p>deleting Vault secrets</p> </li> <li>restarting management-api</li> <li>management-api re-runs the CSR \u2192 Hub signing flow</li> </ul> <p>\u2714 Outbound mTLS is Vault-stored and Hub-signed \u2714 cert-manager is intentionally NOT used</p>"},{"location":"hub-pm4ml-security-architecture/#4-why-two-different-mtls-models-exist","title":"4. Why Two Different mTLS Models Exist","text":"Direction Trust owner Reason Hub \u2192 PM4ML Platform / Infra Standard service identity PM4ML \u2192 Hub Hub (business trust) DFSP onboarding &amp; approval <p>Outbound mTLS is part of DFSP trust establishment, which requires explicit Hub approval and therefore cannot be automated by cert-manager.</p>"},{"location":"hub-pm4ml-security-architecture/#5-jws-application-level-message-signing","title":"5. JWS (Application-Level Message Signing)","text":"<p>JWS is used to ensure message integrity and authenticity, independent of TLS.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        JWS-signed payloads        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     HUB      \u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6   \u2502    PM4ML     \u2502\n\u2502              \u2502  \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500   \u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        JWS-signed payloads        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"hub-pm4ml-security-architecture/#key-model","title":"Key model","text":"<ul> <li> <p>Hub and PM4ML each own:</p> </li> <li> <p>a JWS private key</p> </li> <li>a corresponding public key</li> <li>Public keys are published to MCM Server</li> <li>Private keys are never shared</li> </ul>"},{"location":"hub-pm4ml-security-architecture/#key-properties","title":"Key properties","text":"<ul> <li> <p>JWS keys:</p> </li> <li> <p>\u274c do not expire</p> </li> <li>\u274c have no TTL</li> <li>Rotation is policy-based, not time-based</li> <li>Old keys remain valid for verification until removed</li> </ul>"},{"location":"hub-pm4ml-security-architecture/#6-jws-public-key-publishing-hub-example","title":"6. JWS Public-Key Publishing (Hub example)","text":"<pre><code>cert-manager\n   \u2502\n   \u2502 rotates switch-jws certificate\n   \u25bc\nKubernetes Secret (switch-jws)\n   \u2502\n   \u2502 initContainers:\n   \u2502  - read tls.crt\n   \u2502  - extract public key\n   \u25bc\njws-pubkey-job\n   \u2502\n   \u2502 POST /api/hub/jwscerts\n   \u25bc\nMCM Server\n</code></pre> <ul> <li>cert-manager rotates the certificate</li> <li>Public key is extracted and published</li> <li>MCM stores multiple valid public keys</li> <li>Enables safe JWS key rotation with overlap</li> </ul>"},{"location":"hub-pm4ml-security-architecture/#7-runtime-verification-flow","title":"7. Runtime Verification Flow","text":""},{"location":"hub-pm4ml-security-architecture/#hub-pm4ml","title":"Hub \u2192 PM4ML","text":"<ol> <li> <p>mTLS:</p> </li> <li> <p>PM4ML verifies Hub\u2019s TLS certificate</p> </li> <li> <p>JWS:</p> </li> <li> <p>PM4ML verifies signature using Hub public key from MCM</p> </li> </ol>"},{"location":"hub-pm4ml-security-architecture/#pm4ml-hub","title":"PM4ML \u2192 Hub","text":"<ol> <li> <p>mTLS:</p> </li> <li> <p>Hub verifies PM4ML\u2019s client certificate (Hub-signed)</p> </li> <li> <p>JWS:</p> </li> <li> <p>Hub verifies signature using PM4ML public key from MCM</p> </li> </ol> <p>Both layers must succeed for a request to be accepted.</p>"},{"location":"hub-pm4ml-security-architecture/#8-expiry-rotation-summary","title":"8. Expiry &amp; Rotation Summary","text":"Item Direction Expires? Managed by Rotation method Inbound mTLS cert (PM4ML server) Hub \u2192 PM4ML \u2705 Yes cert-manager Automatic Outbound mTLS cert (Hub as client) Hub \u2192 PM4ML \u2705 Yes Hub + Vault Manual / workflow Inbound mTLS cert (Hub server) PM4ML \u2192 Hub \u2705 Yes cert-manager Automatic Outbound mTLS cert (PM4ML as client) PM4ML \u2192 Hub \u2705 Yes PM4ML + Vault Manual / workflow JWS public key (Hub) Hub \u2192 PM4ML \u274c No MCM-Server Published on rotation JWS public key (PM4ML) PM4ML \u2192 Hub \u274c No MCM-Client Published on rotation JWT token (issued by Hub) PM4ML \u2192 Hub \u2705 Yes Application <code>exp</code> claim"},{"location":"hub-pm4ml-security-architecture/#9-key-takeaways","title":"9. Key Takeaways","text":"<ul> <li>Inbound mTLS \u2192 cert-manager\u2013managed</li> <li>Outbound mTLS \u2192 Vault-stored, Hub-signed</li> <li>JWS \u2192 key-based, no expiry, rotated by policy</li> <li>MCM is the trust registry for JWS public keys</li> </ul>"},{"location":"hub-pm4ml-security-architecture/#10-summary","title":"10. Summary","text":"<p>Hub\u2013PM4ML communication uses cert-manager\u2013managed mTLS for inbound connections, Hub-signed Vault-stored certificates for outbound connections, and JWS for message integrity with public keys distributed via MCM.</p>"},{"location":"platform-architecture-overview/","title":"\ud83c\udfd7\ufe0f Platform Architecture Overview","text":"<p>Hub, PM4ML, and Tazama (Cloud &amp; On-Premise)</p> <p>This document describes the reference architecture for deploying the Mojaloop Hub, PM4ML (Payment Manager for Mojaloop), and Tazama platforms across cloud and on-premise datacenter environments.</p> <p>The architecture focuses on deployment topology, platform responsibilities, security boundaries, and operational separation, without exposing environment-specific or sensitive implementation details.</p> <p>Note This document presents a reference architecture based on commonly adopted deployment patterns. Specific implementations may vary depending on regulatory, organizational, and operational requirements.</p>"},{"location":"platform-architecture-overview/#1-architectural-goals","title":"1. Architectural Goals","text":"<p>The architecture is designed to:</p> <ul> <li>Support secure financial transactions</li> <li>Enable cloud, on-premise, and hybrid deployments</li> <li>Provide operational resilience using a Primary\u2013Standby model</li> <li>Maintain clear trust and responsibility boundaries between platforms</li> <li>Scale predictably based on transaction throughput</li> </ul>"},{"location":"platform-architecture-overview/#2-deployment-topology-primarystandby","title":"2. Deployment Topology (Primary\u2013Standby)","text":"<p>The platform is deployed across two independent sites:</p>"},{"location":"platform-architecture-overview/#primary-site","title":"Primary Site","text":"<ul> <li>Active production environment</li> <li>Handles live transaction traffic</li> <li>Deployed in:</li> <li>Public cloud or</li> <li>On-premise datacenter</li> </ul>"},{"location":"platform-architecture-overview/#standby-site","title":"Standby Site","text":"<ul> <li>Secondary environment with reduced capacity</li> <li>Maintained for service continuity</li> <li>Deployed in a separate cloud region or physical datacenter</li> </ul> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        Secure Connectivity      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Primary Site \u2502  \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6 \u2502  Standby Site \u2502\n\u2502               \u2502                                 \u2502               \u2502\n\u2502 Hub           \u2502                                 \u2502 Hub           \u2502\n\u2502 PM4ML         \u2502                                 \u2502 PM4ML         \u2502\n\u2502 Tazama        \u2502                                 \u2502 Tazama        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Both sites share the same logical architecture. Differences are limited to capacity sizing, not functionality.</p>"},{"location":"platform-architecture-overview/#3-platform-components","title":"3. Platform Components","text":""},{"location":"platform-architecture-overview/#31-mojaloop-hub","title":"3.1 Mojaloop Hub","text":"<ul> <li>Central transaction switching platform</li> <li>Enables interoperability between participants</li> <li>Deployed as containerized services</li> <li>Acts as the trust authority for DFSP onboarding</li> </ul>"},{"location":"platform-architecture-overview/#32-pm4ml-payment-manager-for-mojaloop","title":"3.2 PM4ML (Payment Manager for Mojaloop)","text":"<ul> <li>DFSP-facing payment management platform</li> <li> <p>Can be deployed:</p> </li> <li> <p>Per DFSP, or</p> </li> <li>As a shared service</li> <li>Supports both cloud-hosted and on-premise environments</li> <li>Establishes business trust with the Hub</li> </ul>"},{"location":"platform-architecture-overview/#33-tazama","title":"3.3 Tazama","text":"<ul> <li>Transaction monitoring and fraud detection platform</li> <li>Consumes transaction events for analysis</li> <li>Can be deployed centrally or regionally</li> <li>Operates independently of transaction processing paths</li> </ul>"},{"location":"platform-architecture-overview/#4-infrastructure-architecture","title":"4. Infrastructure Architecture","text":""},{"location":"platform-architecture-overview/#runtime-platform","title":"Runtime Platform","text":"<ul> <li>Kubernetes used as the common orchestration layer</li> <li>Consistent deployment patterns across environments</li> </ul>"},{"location":"platform-architecture-overview/#networking","title":"Networking","text":"<ul> <li>Private, encrypted communication between platforms</li> <li>Hybrid connectivity supported for cloud \u2194 on-premise scenarios</li> </ul>"},{"location":"platform-architecture-overview/#traffic-management","title":"Traffic Management","text":"<ul> <li>Controlled ingress and egress for platform services</li> <li>Clear separation between internal and external traffic paths</li> </ul>"},{"location":"platform-architecture-overview/#data-services","title":"Data Services","text":"<ul> <li>Databases and messaging systems sized per expected throughput</li> <li>Logical isolation maintained between platforms</li> </ul>"},{"location":"platform-architecture-overview/#5-security-architecture-high-level","title":"5. Security Architecture (High Level)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      mTLS + JWS       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Hub   \u2502  \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6   \u2502  PM4ML  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502  Transaction Events\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Tazama  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"platform-architecture-overview/#security-principles","title":"Security Principles","text":"<ul> <li>Encrypted communication for all inter-platform traffic</li> <li>Strong platform identity and authentication</li> <li>Separation of infrastructure trust and business trust</li> <li>Centralized secrets and key management</li> </ul> <p>Detailed mTLS and JWS mechanisms are documented separately.</p>"},{"location":"platform-architecture-overview/#6-availability-and-resilience","title":"6. Availability and Resilience","text":"<ul> <li>High availability within each site</li> <li>No active-active transaction processing across sites</li> <li>Standby site maintained in a ready state</li> <li>Recovery and failover procedures defined outside this document</li> </ul>"},{"location":"platform-architecture-overview/#7-operational-model","title":"7. Operational Model","text":"<ul> <li>Infrastructure provisioned using automation</li> <li>Platform deployments follow GitOps practices</li> <li>Centralized monitoring, logging, and alerting</li> <li>Consistent operations across cloud and on-premise environments</li> </ul>"},{"location":"platform-architecture-overview/#8-scope-clarification","title":"8. Scope Clarification","text":"<p>This document covers:</p> <ul> <li>Platform roles and responsibilities</li> <li>Deployment topology</li> <li>High-level security and connectivity patterns</li> </ul> <p>This document does not include:</p> <ul> <li>Environment-specific configurations</li> <li>Backup and restore procedures</li> <li>Incident response or failover runbooks</li> <li>Regulatory or compliance controls</li> </ul>"},{"location":"platform-architecture-overview/#9-key-takeaways","title":"9. Key Takeaways","text":"<ul> <li>A single architecture supports cloud, on-premise, and hybrid deployments</li> <li>Primary\u2013Standby model balances resilience and cost</li> <li>Hub, PM4ML, and Tazama have clearly separated responsibilities</li> <li>Security is enforced at both transport and application layers</li> </ul>"},{"location":"platform-architecture-overview/#10-summary","title":"10. Summary","text":"<p>The Mojaloop Hub, PM4ML, and Tazama platforms are deployed using a consistent, secure, and flexible architecture that supports cloud and on-premise environments while maintaining clear trust boundaries and operational resilience.</p>"}]}